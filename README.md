# parallel-text-processing-handler
A text processing system for rule-based analysis of the 'I Have a Dream' speech.
âœ¨ Parallel Text Processing Handler â€“ Speech Analysis Project
By Hepshibha Majji


ğŸ“Œ 1. Project Overview

This project is a Parallel Text Processing System built to analyze the speech â€œI Have a Dreamâ€ by Martin Luther King Jr.
The goal is to demonstrate how large text can be processed efficiently using:

Regex-based rule detection

Parallel Processing (multiprocessing)

Automated sentence scoring

Database storage (SQLite)

Visualisation using charts

This pipeline represents a complete text analytics engine, built step-by-step across milestones.

ğŸ“‚ 2. Project Structure

<img width="500" height="500" alt="Image Dec 4, 2025, 09_30_33 PM" src="https://github.com/user-attachments/assets/528143e5-d178-453f-a80b-a50f6b5fdae8" />



ğŸ§  3. Problem Statement

To design a Parallel Text Processing Handler capable of:

Reading and splitting large text efficiently

Detecting meaningful patterns using Regex rules

Processing text using parallel multiprocessing

Storing results in CSV + SQLite database

Visualizing insights from the processed text

ğŸ¯ 4. Why This Data?

Even though the dataset is a speech, it is rich in:

Repeated thematic words (freedom, justice, dream)

Emotion-heavy sentences

Locations, metaphors, and political references

Clear structure useful for rule-based analysis

This makes it ideal for pattern detection, parallel processing, and building a text analytics pipeline.

âš™ï¸ 5. Technologies Used

<img width="500" height="500" alt="Image Dec 4, 2025, 09_38_47 PM" src="https://github.com/user-attachments/assets/5db990b7-0d17-4762-97c7-ff8d1ec81ed4" />



ğŸ§© 6. System Architecture

<img width="500" height="500" alt="Image_q5o5anq5o5anq5o5" src="https://github.com/user-attachments/assets/bfb46dae-c742-4e63-a01b-d69faef1f44e" />



ğŸ” 7. Rule Categories Used

A total of 10 rule patterns were created:

Freedom rule

Dream rule

Justice rule

Hope rule

Metaphor rule

Location rule

Positive emotion rule

Negative emotion rule

Repetition rule

People reference rule

Each rule uses regex to detect specific themes or sentence patterns.

ğŸš€ 8. How the Pipeline Works


âœ” Step 1 â€“ Data Reading

Loads the speech text from the input folder.

âœ” Step 2 â€“ Chunk Splitting

Text is divided into paragraphs or grouped lines.

âœ” Step 3 â€“ Rule Detection

Each chunk is scanned using regex patterns.

âœ” Step 4 â€“ Parallel Processing

Word frequency counting is done using multiprocessing.

âœ” Step 5 â€“ Scoring

Chunks are scored based on how many rules they match.

âœ” Step 6 â€“ Storage

Output is saved as:

results_dream.csv

matches_all_chunks.csv

chunk_scores.csv

results_dream.db (SQLite DB)

âœ” Step 7 â€“ Visualisation

Pie chart â†’ Rule distribution
Bar chart â†’ Word frequency
Histogram â†’ Chunk score distribution

ğŸ“Š 9. Output Files

Your output folder will contain:

CSV files

results_dream.csv- This file contains word frequency counts from the entire speech.

matches_all_chunks.csv-stores every single sentence that matched a rule, along with its chunk number and rule name

chunk_scores.csv- shows how many rules each chunk matched- a "complexity score."

Database

results_dream.db-  A structured database version of your output.

Charts

rule_distribution_pie.png-  shows which rules matched the most sentences.

word_frequency_bar.png- Top 15 meaningful words

chunk_score_histogram.png- shows how many chunks matched 0,1,1,3+ rules.

ğŸ§ª 10. Sample Results


âœ” Rule Matches

Shows which sentences triggered which rule.

âœ” Word Frequencies

Identifies top meaningful words in the speech.

âœ” Chunk Scores

Shows how many rules each chunk satisfies.

âš ï¸ 11. Challenges Faced

Identifying the right regex patterns for meaningful detection

Splitting text cleanly into sentences and chunks

Handling inconsistent formatting inside the dataset

Combining multiple rule outputs into a clean structured system

Managing multiple output formats (CSV + DB + charts)

ğŸ“ 12. Key Learnings

Working with large text using automation

Designing custom rules using regex

Implementing multiprocessing for faster workflows

Structuring data for real-world analysis

Creating a complete processing pipeline end-to-end

ğŸ“ˆ 13. Future Scope

Add machine learning models for text classification

Add sentiment analysis and entity extraction

Build a web dashboard for visualising results

Support multiple datasets beyond speeches

âœ”ï¸ 14. How to Run This Project


Step 1: Clone Repository
git clone https://github.com/Hepshibha-787/parallel-text-processing-handler

Step 2: Open the Notebook
code/final_notebook.ipynb

Step 3: Install Requirements (if any)
pip install matplotlib

Step 4: Run All Cells

The notebook automatically:

Reads input

Runs rules

Creates outputs

Saves results

Generates visualisation

ğŸ 15. Conclusion

This project demonstrates an end-to-end parallel text processing system that converts raw text into structured insights using rules, scoring, storage, and visualization. It provides a strong foundation for more advanced NLP and automation systems.
